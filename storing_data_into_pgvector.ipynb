{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-extractors-entity\n",
    "%pip install llama-index-vector-stores-postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0157bcf",
   "metadata": {},
   "source": [
    "**Installing pgvcector extension**\n",
    "CREATE EXTENSION vector;\n",
    "CREATE TABLE documents (\n",
    "    id serial PRIMARY KEY,\n",
    "    content text,\n",
    "    embedding vector(1536)  -- if using OpenAI\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import nest_asyncio\n",
    "import os\n",
    "import pandas as pd\n",
    "from llama_index.core import Settings, Document, VectorStoreIndex\n",
    "from llama_index.core.extractors.metadata_extractors import SummaryExtractor\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()  # Loads variables from .env file\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(api_key=OPENAI_API_KEY,temperature=0.1, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376db5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "load_dotenv()\n",
    "# Database connection details\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = \"5432\"  # Default PostgreSQL port\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "TABLE_NAME = \"hts_data\" \n",
    "connection_string = \"postgresql://postgres:\"+str(os.getenv(\"DB_PASSWORD\"))+\"@1.2.3.4:5432/postgres\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca16f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file.docs import PDFReader\n",
    "from pathlib import Path\n",
    "loader = PDFReader()\n",
    "documents = loader.load_data(file=Path(\"./data/Cristiano_Ronaldo.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef5970",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "* You're telling the system:\n",
    "\n",
    "* \"Store vectors of size 1536.\"\n",
    "\n",
    "* \"Use cosine similarity to compare them.\"\n",
    "\n",
    "* \"Use HNSW indexing with these performance/accuracy trade-offs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0364b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "464608bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 39/39 [00:00<00:00, 364.19it/s]\n",
      "Generating embeddings: 100%|██████████| 98/98 [00:06<00:00, 14.85it/s]\n"
     ]
    }
   ],
   "source": [
    "url = make_url(connection_string)\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=DB_NAME,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"ronaldopdf_vector\",\n",
    "    embed_dim=1536,  # openai embedding dimension text-embedding-ada-002\n",
    "    hnsw_kwargs={\n",
    "        \"hnsw_m\": 16,\n",
    "        \"hnsw_ef_construction\": 64,\n",
    "        \"hnsw_ef_search\": 40,\n",
    "        \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "    },\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, show_progress=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
